# -*- coding: utf-8 -*-
"""MiniP1_1_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QhTOAJQR1ex-h21OD8iRpGrqnqXn3J7Q

PART 1:

Q1:
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from matplotlib.colors import ListedColormap

X, y = make_classification(n_samples=1000, n_features=2, n_classes=2, n_redundant=0, random_state=13, n_clusters_per_class=1, class_sep=1.8)
plt.scatter(X[:,0], X[:,1], c=y)

"""Q2:"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, SGDClassifier

x_train, x_test, y_train, y_test = train_test_split(X, y,random_state=13, test_size = 0.2)

model1 = LogisticRegression(solver='sag', max_iter=210)
model1.fit(x_train, y_train)
model1.predict(x_test)

print("Accuracy of test data: %", model1.score(x_test, y_test)*100)
print("Accuracy of train data: %", model1.score(x_train, y_train)*100)

model2 = SGDClassifier(loss='log_loss', random_state=13, max_iter=2000)
model2.fit(x_train, y_train)
model2.predict(x_test)

print("Accuracy of test data: %", model2.score(x_test, y_test)*100)
print("Accuracy of train data: %", model2.score(x_train, y_train)*100)

"""Q3:"""

colors = np.array(['blue', 'red'])
plt.scatter(X[:, 0], X[:, 1], c=colors[y])
plt.show()

model3 = LogisticRegression()
model3.fit(X,y)

from mlxtend.plotting import plot_decision_regions

plot_decision_regions(X, y, clf=model3)

"""OR:"""

# برای نمایش متفاوت نمونه هایی که اشتباه طبقه بندی شدند از کد زیر استفاده میکنیم
def plot_decision_boundary(model, X, y, title):
    h = .02  # مشخص کردن سایز هر مرحله

    # تشکیل نقشه رنگ
    cmap_light = ListedColormap(['#00FF00', '#800080'])
    cmap_bold = ListedColormap(['#FF0000', '#0000FF'])

    # رسم نواحی تصمیم گیری
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.figure()
    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)

    # رسم نقاط
    correct_predictions = model.predict(X) == y
    incorrect_predictions = ~correct_predictions

    plt.scatter(X[correct_predictions, 0], X[correct_predictions, 1], c=y[correct_predictions], cmap=cmap_bold, marker='o', edgecolor='k', s=20, label='Correct')
    plt.scatter(X[incorrect_predictions, 0], X[incorrect_predictions, 1], marker='8', color='yellow', s=50, label='Misclassified')

    plt.title(title)
    plt.legend()
    plt.show()


plot_decision_boundary(model3, X, y, 'Logistic Regression Decision Boundary')

"""Q4:"""

A, b = make_classification(n_samples=1000, n_features=2, n_classes=2, n_redundant=0, random_state=13, class_sep=0.8, n_clusters_per_class=2)
plt.scatter(A[:,0], A[:,1], c=b)

a_train, a_test, b_train, b_test = train_test_split(A, b,random_state=13, test_size = 0.2)

model5 = LogisticRegression(solver='sag', max_iter=210)
model5.fit(a_train, b_train)
model5.predict(a_test)

print("Accuracy of test data: %", model5.score(a_test, b_test)*100)
print("Accuracy of train data: %", model5.score(a_train, b_train)*100)

model6 = SGDClassifier(loss='log_loss', random_state=13, max_iter=2000)
model6.fit(a_train, b_train)
model6.predict(a_test)

print("Accuracy of test data: %", model6.score(a_test, b_test)*100)
print("Accuracy of train data: %", model6.score(a_train, b_train)*100)

model7 = LogisticRegression()
model7.fit(A,b)
plot_decision_regions(A, b, clf=model7)

"""Q5:"""

X2, y2 = make_classification(n_samples=1000, n_features=2, n_classes=3, n_redundant=0, random_state=13, n_clusters_per_class=1, class_sep=1.8)
plt.scatter(X2[:,0], X2[:,1], c=y2)
print(X2.shape, y2.shape)

from sklearn.metrics import accuracy_score, classification_report
# آموزش مدل به روش لجستیک رگرسیون

x2_train, x2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=13)
logreg_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=13)
logreg_model.fit(x2_train, y2_train)

# عملیات پردیک بر روی داده های تست
logreg_predictions = logreg_model.predict(x2_test)

# محاسبه و نمایش دقت
accuracy = accuracy_score(y2_test, logreg_predictions)
print("Accuracy: %", accuracy*100)

# تابع رسم نواحی تصمیم گیری
def plot_decision_boundary(model, X2, y2, title):
    h = .02  # Step size in the mesh

    # تشکیل نقشه رنگ
    cmap_light = ListedColormap(['#FFAAAA', '#008000', '#FFA500'])
    cmap_bold = ListedColormap(['#FF0000', '#0000FF', '#00FF00'])

    # رسم نواحی تصمیم گیری
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.figure()
    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)

    # رسم نقاط
    correct_predictions = model.predict(X2) == y2
    incorrect_predictions = ~correct_predictions

    plt.scatter(X2[correct_predictions, 0], X2[correct_predictions, 1], c=y2[correct_predictions], cmap=cmap_bold, marker='o', edgecolor='k', s=20, label='Correct')
    plt.scatter(X2[incorrect_predictions, 0], X2[incorrect_predictions, 1], marker='8', color='yellow', s=50, label='Misclassified')

    plt.title(title)
    plt.legend()
    plt.show()


plot_decision_boundary(logreg_model, X2, y2, 'Logistic Regression Decision Boundary')